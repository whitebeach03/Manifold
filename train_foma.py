import torch
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import torch.nn.functional as F

def foma_inputspace_per_class(x_batch, y_batch, num_classes, lam=0.5, k=20):
    B, C, H, W = x_batch.shape
    D = C * H * W
    x_flat = x_batch.view(B, -1)
    y_onehot = F.one_hot(y_batch, num_classes).float()
    x_aug_list, y_aug_list = [], []

    for cls in range(num_classes):
        mask = (y_batch == cls)
        if mask.sum() < 2:
            continue
        X_cls = x_flat[mask]
        Y_cls = y_onehot[mask]
        A = torch.cat([X_cls, Y_cls], dim=1)
        U, S, Vt = torch.linalg.svd(A, full_matrices=False)
        n = S.shape[0]
        k = min(k, n)
        scale = torch.cat([
            torch.ones(k, device=A.device),
            torch.full((n - k,), lam, device=A.device)
        ])
        S_scaled = S * scale
        A_aug = U @ torch.diag(S_scaled) @ Vt
        X_aug = A_aug[:, :D].view(-1, C, H, W)
        Y_aug = F.softmax(A_aug[:, D:], dim=1)
        x_aug_list.append(X_aug)
        y_aug_list.append(Y_aug)

    if len(x_aug_list) == 0:
        return None, None
    x_aug_total = torch.cat(x_aug_list, dim=0)
    y_aug_total = torch.cat(y_aug_list, dim=0)
    return x_aug_total, y_aug_total

# def show_augmented_images_per_class(x_batch, y_batch, num_classes=10, lam=0.5, k=20, max_per_class=5):
#     x_aug, y_aug = foma_inputspace_per_class(x_batch, y_batch, num_classes, lam=lam, k=k)
#     if x_aug is None:
#         print("æ‹¡å¼µã§ãã‚‹ã‚¯ãƒ©ã‚¹ãŒãƒãƒƒãƒå†…ã«å­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
#         return

#     pred_labels = y_aug.argmax(dim=1)

#     # ã‚¯ãƒ©ã‚¹ã”ã¨ã«ç”»åƒã‚’è¡¨ç¤º
#     fig, axs = plt.subplots(num_classes, max_per_class, figsize=(max_per_class * 2, num_classes * 2))
#     axs = axs if num_classes > 1 else [axs]

#     for cls in range(num_classes):
#         # ã‚¯ãƒ©ã‚¹ã«å±ã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
#         indices = (pred_labels == cls).nonzero(as_tuple=True)[0][:max_per_class]
#         for j, idx in enumerate(indices):
#             img = x_aug[idx].cpu()
#             img = img.permute(1, 2, 0).numpy()  # (C, H, W) â†’ (H, W, C)
#             img = (img - img.min()) / (img.max() - img.min())  # æ­£è¦åŒ–ï¼ˆè¡¨ç¤ºã®ãŸã‚ï¼‰
#             axs[cls][j].imshow(img)
#             axs[cls][j].axis('off')
#             axs[cls][j].set_title(f"Class {cls}")
#         # ç©ºæ¬„ã‚’åŸ‹ã‚ã‚‹
#         for j in range(len(indices), max_per_class):
#             axs[cls][j].axis('off')

#     plt.tight_layout()
#     plt.show()

# # ğŸ”§ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
# if __name__ == "__main__":
#     transform = transforms.Compose([transforms.ToTensor()])
#     dataset = datasets.STL10(root="./data", split="train", download=True, transform=transform)
#     loader = DataLoader(dataset, batch_size=256, shuffle=True)

#     x_batch, y_batch = next(iter(loader))
#     x_batch, y_batch = x_batch.cuda(), y_batch.cuda()

#     show_augmented_images_per_class(x_batch, y_batch, num_classes=10, lam=0.5, k=20)


def compare_original_and_foma(x_batch, y_batch, num_classes=10, lam=0.5, k=20, max_per_class=5):
    x_aug, y_aug = foma_inputspace_per_class(x_batch, y_batch, num_classes, lam=lam, k=k)
    if x_aug is None:
        print("æ‹¡å¼µå¯èƒ½ãªã‚¯ãƒ©ã‚¹ãŒãƒãƒƒãƒã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    pred_labels = y_aug.argmax(dim=1)

    fig, axs = plt.subplots(num_classes, max_per_class * 2, figsize=(max_per_class * 4, num_classes * 2))

    for cls in range(num_classes):
        # ã‚¯ãƒ©ã‚¹ã«å±ã™ã‚‹æ‹¡å¼µç”»åƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        indices = (pred_labels == cls).nonzero(as_tuple=True)[0][:max_per_class]
        for j, idx in enumerate(indices):
            # æ‹¡å¼µç”»åƒ
            img_aug = x_aug[idx].cpu()
            img_aug = img_aug.permute(1, 2, 0).numpy()
            img_aug = (img_aug - img_aug.min()) / (img_aug.max() - img_aug.min())

            # å¯¾å¿œã™ã‚‹å…ƒç”»åƒï¼ˆå…ƒãƒãƒƒãƒã®ã†ã¡ã€åŒã˜ã‚¯ãƒ©ã‚¹ã®ç”»åƒã‚’ j ç•ªç›®ã«é¸ã¶ï¼‰
            original_indices = (y_batch == cls).nonzero(as_tuple=True)[0]
            if len(original_indices) <= j:
                continue
            img_orig = x_batch[original_indices[j]].cpu()
            img_orig = img_orig.permute(1, 2, 0).numpy()
            img_orig = (img_orig - img_orig.min()) / (img_orig.max() - img_orig.min())

            # è¡¨ç¤ºï¼šå·¦ã«å…ƒç”»åƒã€å³ã«FOMAç”»åƒ
            axs[cls][2 * j].imshow(img_orig)
            axs[cls][2 * j].axis('off')
            axs[cls][2 * j].set_title(f"Orig C{cls}")

            axs[cls][2 * j + 1].imshow(img_aug)
            axs[cls][2 * j + 1].axis('off')
            axs[cls][2 * j + 1].set_title(f"FOMA C{cls}")

        # ç©ºæ¬„åŸ‹ã‚
        for j in range(len(indices), max_per_class):
            axs[cls][2 * j].axis('off')
            axs[cls][2 * j + 1].axis('off')

    plt.tight_layout()
    plt.savefig("FOMA-image.png")

# ğŸ”§ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
if __name__ == "__main__":
    transform = transforms.Compose([transforms.ToTensor()])
    dataset = datasets.STL10(root="./data", split="train", download=True, transform=transform)
    loader = DataLoader(dataset, batch_size=256, shuffle=True)
    x_batch, y_batch = next(iter(loader))
    x_batch, y_batch = x_batch.cuda(), y_batch.cuda()

    compare_original_and_foma(x_batch, y_batch, num_classes=10, lam=0.5, k=10)